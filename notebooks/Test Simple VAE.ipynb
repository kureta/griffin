{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fe00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import LitVAE, AudioDataset, next_power_of_2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchaudio.transforms import GriffinLim\n",
    "import numpy as np\n",
    "from scipy.spatial import geometric_slerp\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from torchcrepe.convert import frequency_to_bins, cents_to_bins\n",
    "from torchcrepe import predict\n",
    "from torchcrepe.decode import argmax\n",
    "import torchvision.transforms.functional as tvf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7660e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(n_dims=64):\n",
    "    x = np.random.standard_normal(n_dims)\n",
    "    x = x / np.sqrt(x.dot(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = GriffinLim(n_fft=2048, hop_length=512, power=1.0, n_iter=128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_checkpoint(v=None):\n",
    "    base_path = Path('../lightning_logs/')\n",
    "    \n",
    "    if v is None:\n",
    "        version = 0    \n",
    "        for f in base_path.iterdir():\n",
    "            v = int(f.name.split('_')[1])\n",
    "            version = v if v > version else version\n",
    "    else:\n",
    "        version = v\n",
    "    \n",
    "    base_path = base_path / f'version_{version}/checkpoints'\n",
    "    checkpoint = next(base_path.glob('*.ckpt'))\n",
    "    \n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "model = LitVAE.load_from_checkpoint(latest_checkpoint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170879b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "start = sample(64)\n",
    "s = 1.\n",
    "e = 0.\n",
    "block = 64\n",
    "for i in range(50):\n",
    "    end = sample(64)\n",
    "    zs.append(geometric_slerp(start, end, np.linspace(0, 1, block, endpoint=False)) * (np.linspace(s, e, block))[:, None])\n",
    "    start = end\n",
    "    s, e = e, s\n",
    "zs = np.concatenate(zs, axis=0)\n",
    "\n",
    "zs = torch.from_numpy(zs.astype('float32')).cuda()\n",
    "cs = torch.zeros(zs.shape[0], 360).cuda()\n",
    "freq = frequency_to_bins(torch.Tensor([98.]), torch.round)\n",
    "cs[:, int(freq)] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b31c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = torch.cat([zs.T.unsqueeze(0), cs.T.unsqueeze(0)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d383afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_hat = model.vae.decoder(feat)\n",
    "    y_hats = (x_hat * 1024).squeeze(0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917894a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = y_hats.cpu().numpy()\n",
    "\n",
    "# plt.matshow(s)\n",
    "# plt.show()\n",
    "\n",
    "zeros = torch.zeros(y_hats.shape[0], 1, device=y_hats.device)\n",
    "sound = gl(torch.cat([zeros, y_hats], dim=1).T)\n",
    "Audio(sound.cpu().numpy(), rate=44100, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c54e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/kureta/Music/cello/Cello Samples/BachMinu1-00000-.wav'\n",
    "y, sr = librosa.load(PATH, mono=True, sr=44100)\n",
    "s = np.abs(librosa.stft(y, n_fft=2048, hop_length=512)) / 1024\n",
    "plt.matshow(s.T)\n",
    "plt.show()\n",
    "\n",
    "Audio(y, rate=44100, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ea8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREPE_SAMPLE_RATE = 16000\n",
    "sample_rate = 44100\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "crepe_hop_length = next_power_of_2(hop_length * CREPE_SAMPLE_RATE / sample_rate)\n",
    "_, _, probs = predict(torch.from_numpy(y).unsqueeze(0), sample_rate=sample_rate, hop_length=crepe_hop_length,\n",
    "                      return_periodicity=True, device='cuda', decoder=argmax, batch_size=512)\n",
    "probs = probs.argmax(dim=1)[0]\n",
    "probs = tvf.resize(probs.unsqueeze(0).unsqueeze(0), [1, s.shape[1]]).squeeze(1)\n",
    "probs = F.one_hot(probs[0], 360).T.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_hat, _, _, _ = model.vae(torch.from_numpy(s[1:]).unsqueeze(0).cuda(), probs)\n",
    "    y_hats = (x_hat * 1024).squeeze(0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(y_hats.cpu().numpy())\n",
    "plt.show()\n",
    "\n",
    "zeros = torch.zeros(y_hats.shape[0], 1, device=y_hats.device)\n",
    "sound = gl(torch.cat([zeros, y_hats], dim=1).T)\n",
    "Audio(sound.cpu().numpy(), rate=44100, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8316be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
