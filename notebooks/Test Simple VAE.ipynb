{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fe00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import LitVAE, AudioDataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchaudio.transforms import GriffinLim\n",
    "import numpy as np\n",
    "from scipy.spatial import geometric_slerp\n",
    "from IPython.display import Audio\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4443b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7660e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(n_dims=64):\n",
    "    x = np.random.standard_normal(n_dims)\n",
    "    x = x / np.sqrt(x.dot(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = GriffinLim(n_fft=2048, hop_length=512, power=1.0, n_iter=128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_checkpoint(v=None):\n",
    "    base_path = Path('../lightning_logs/')\n",
    "    \n",
    "    if v is None:\n",
    "        version = 0    \n",
    "        for f in base_path.iterdir():\n",
    "            v = int(f.name.split('_')[1])\n",
    "            version = v if v > version else version\n",
    "    else:\n",
    "        version = v\n",
    "    \n",
    "    base_path = base_path / f'version_{version}/checkpoints'\n",
    "    checkpoint = next(base_path.glob('*.ckpt'))\n",
    "    \n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "model = LitVAE.load_from_checkpoint(latest_checkpoint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170879b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "start = sample(64)\n",
    "s = 8.\n",
    "e = s\n",
    "block = 128\n",
    "for i in range(32):\n",
    "    end = sample(64)\n",
    "    zs.append(geometric_slerp(start, end, np.linspace(0, 1, block, endpoint=False)) * (np.linspace(s, e, block))[:, None])\n",
    "    start = end\n",
    "    s, e = e, s\n",
    "zs = np.concatenate(zs, axis=0)\n",
    "\n",
    "zs = torch.from_numpy(zs.astype('float32')).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d383afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_hat = model.vae.decoder(zs)\n",
    "    y_hats = x_hat * 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917894a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = y_hats.cpu().numpy()\n",
    "\n",
    "# plt.matshow(s)\n",
    "# plt.show()\n",
    "\n",
    "zeros = torch.zeros(y_hats.shape[0], 1, device=y_hats.device)\n",
    "sound = gl(torch.cat([zeros, y_hats], dim=1).T)\n",
    "Audio(sound.cpu().numpy(), rate=44100, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c54e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/kureta/Music/cello/Cello Samples/BachMinu1-00000-.wav'\n",
    "y, sr = librosa.load(PATH, mono=True, sr=44100)\n",
    "s = np.abs(librosa.stft(y, n_fft=2048, hop_length=512)) / 1024\n",
    "plt.matshow(s.T)\n",
    "plt.show()\n",
    "\n",
    "Audio(y, rate=44100, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_hat, _, _, _ = model.vae(torch.from_numpy(s[1:]).T.cuda())\n",
    "    y_hats = x_hat * 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(y_hats.cpu().numpy())\n",
    "plt.show()\n",
    "\n",
    "zeros = torch.zeros(y_hats.shape[0], 1, device=y_hats.device)\n",
    "sound = gl(torch.cat([zeros, y_hats], dim=1).T)\n",
    "Audio(sound.cpu().numpy(), rate=44100, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255dec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
